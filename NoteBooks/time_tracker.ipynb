{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeStampExtractor:\n",
    "    def __init__(self, video_path, output_dir='output/frames/'):\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        self.model = YOLO('Models/timestamp.pt')\n",
    "        self.api_key = api_key\n",
    "        self.video_path = video_path\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def extract_first_detection(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        frame_saved = False\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_saved:\n",
    "                break\n",
    "            \n",
    "            # Perform inference on the frame\n",
    "            results = self.model(frame)\n",
    "            \n",
    "            # Extract bounding boxes\n",
    "            bboxes = results[0].boxes.xyxy\n",
    "            \n",
    "            # Check if only one object is detected\n",
    "            if len(bboxes) == 1:\n",
    "                # Crop the frame to the bounding box of the detected object\n",
    "                x1, y1, x2, y2 = map(int, bboxes[0])\n",
    "                cropped_frame = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                # Save the cropped frame\n",
    "                frame_filename = os.path.join(self.output_dir, 'detected_object.jpg')\n",
    "                cv2.imwrite(frame_filename, cropped_frame)\n",
    "                print(f'Saved: {frame_filename}')\n",
    "                \n",
    "                # Set the flag to True to ensure only one frame is saved\n",
    "                frame_saved = True\n",
    "\n",
    "        cap.release()\n",
    "        return frame_filename if frame_saved else None\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def extract_timestamp(self, image_path):\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "\n",
    "        schema = \"\"\"HH:MM:SS\"\"\"\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"Extract date and time using your multimodal capabilities and return reponse with respect to given {schema}, If it is a blank image return '00:00:00' and don't give any code, notations and English explanation\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "            \n",
    "            response=response.json()\n",
    "            content = response.get('choices')[0].get(\"message\").get('content')\n",
    "            print(\"**********\",content)\n",
    "            return content\n",
    "        except Exception as ex:\n",
    "            print(\"Exception: ------> In TIMETRACKER\", ex)\n",
    "            return None\n",
    "\n",
    "    def cleanup(self):\n",
    "        if os.path.exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "            print(f\"Cleaned up: {self.output_dir}\")\n",
    "\n",
    "    def run(self):\n",
    "        frame_path = self.extract_first_detection()\n",
    "        if frame_path:\n",
    "            return self.extract_timestamp(frame_path)\n",
    "        else:\n",
    "            self.cleanup()\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_time(video_path):\n",
    "    return TimeStampExtractor(video_path).run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
